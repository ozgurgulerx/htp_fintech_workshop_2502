{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building with AutoGen \n",
    "### Please Complete the **[environment setup](part1_environment_setup.ipynb)** first before progressing with the notebook!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Starting Building with AutoGen \n",
    "Let's start with a simple example of how AutoGen is integrated Azure OpenAI. \n",
    "The example will confirm Azure OpenAI endpoints and keys are correctly configured and that AutoGen is installed and working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Hello! Are you working?\n",
      "---------- azure_test_agent ----------\n",
      "Hello! Yes, I'm here and ready to help you. What do you need assistance with?\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a minimal Azure OpenAI client.\n",
    "azure_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create an assistant agent with a simple system message.\n",
    "agent = AssistantAgent(\n",
    "    name=\"azure_test_agent\",\n",
    "    model_client=azure_client,\n",
    "    system_message=\"You are a helpful Azure test assistant.\"\n",
    ")\n",
    "\n",
    "async def test_connection():\n",
    "    user_input = \"Hello! Are you working?\"\n",
    "    await Console(agent.run_stream(task=user_input))\n",
    "\n",
    "await test_connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **autogen** framework provides multiple agent roles—such as `AssistantAgent`, `UserAgent`, `FunctionAgent` (for function or tool calls), and `MultiAgent` (for orchestrating multiple participants)—each designed for specialized behaviors in a conversation. For example:\n",
    "\n",
    "- `AssistantAgent`: Represents a helpful AI assistant.\n",
    "- `FunctionAgent`: Handles specific tools or API calls.\n",
    "- `MultiAgent`: Coordinates interactions among different agents.\n",
    "\n",
    "This modular design makes it straightforward to build and manage multi-turn, multi-role dialogues, assigning clear, distinct responsibilities to each agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AssistantAgent` we used here is a high-level wrapper around a language model client (such as an AzureOpenAI model) that manages:\n",
    "\n",
    "1. **Conversational Context**: It keeps track of all previous exchanges and organizes them into a coherent dialog.\n",
    "2. **System or Instruction Prompt**: You can give it a “system message” that defines the overarching instructions or persona, such as:\n",
    "   > \"You are a helpful Azure test assistant.\"\n",
    "\n",
    "By consolidating these elements, `AssistantAgent` simplifies the process of building chat interfaces on top of LLMs, handling how user messages and model responses flow, and ensuring all conversation logic is neatly contained in a single agent object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Function Calling Example \n",
    "\n",
    "Function calling in the context of modern LLMs (Large Language Models) lets the model “call” a function (or tool) whenever it detects the user’s query needs that function’s capabilities. Rather than returning a text-only answer, the LLM returns structured arguments for the function, which your application or framework executes. \\\n",
    "\n",
    "In AutoGen’s AssistantAgent, every function you register is treated as a “tool” that the LLM can invoke. When a user prompt suggests one of those tools is needed, the model produces a structured “function call” specifying which tool to use and the arguments to pass. The AssistantAgent runs that function in your Python environment, then feeds the result back to the model. Finally, the model incorporates that real-world data—whether weather forecasts, currency exchanges, or local times—into its final, user-facing response. This design keeps things neat: the LLM decides what needs doing, and your Python code handles how it’s done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n",
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_9C5GX80bp0EZYyvzoV1GFtBJ', arguments='{\"city\":\"Berlin\"}', name='get_weather')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='The current weather in Berlin is 25°C, sunny.', call_id='call_9C5GX80bp0EZYyvzoV1GFtBJ', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "The current weather in Berlin is 25°C, sunny.\n",
      "\n",
      "\n",
      "---------- user ----------\n",
      "Actually, could you also convert 100 USD to EUR?\n",
      "---------- user ----------\n",
      "Actually, could you also convert 100 USD to EUR?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_csjAda59wYfBTg4egrbkK2YU', arguments='{\"amount\":100,\"from_currency\":\"USD\",\"to_currency\":\"EUR\"}', name='convert_currency')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='100.0 USD is approximately 110.00 EUR.', call_id='call_csjAda59wYfBTg4egrbkK2YU', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "100.0 USD is approximately 110.00 EUR.\n",
      "\n",
      "\n",
      "---------- user ----------\n",
      "What's the local time in Tokyo right now?\n",
      "---------- user ----------\n",
      "What's the local time in Tokyo right now?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_ZHay0Di0XPhq4guZzeLKxQxR', arguments='{\"tz\":\"Asia/Tokyo\"}', name='get_time_in')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='The current local time in Asia/Tokyo is 09:00 AM.', call_id='call_ZHay0Di0XPhq4guZzeLKxQxR', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "The current local time in Asia/Tokyo is 09:00 AM.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# 1) Define three different \"tool\" functions that your LLM might call.\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns a fake weather report for demonstration.\"\"\"\n",
    "    return f\"The current weather in {city} is 25°C, sunny.\"\n",
    "\n",
    "async def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"Returns a simple stub result for currency conversion.\"\"\"\n",
    "    # In real scenarios, you'd call a currency conversion API here.\n",
    "    # We'll just do a mock 1:1.1 ratio for demonstration.\n",
    "    conversion_rate = 1.1\n",
    "    converted_amount = amount * conversion_rate\n",
    "    return f\"{amount} {from_currency.upper()} is approximately {converted_amount:.2f} {to_currency.upper()}.\"\n",
    "\n",
    "async def get_time_in(tz: str) -> str:\n",
    "    \"\"\"Returns a mock local time for the given timezone.\"\"\"\n",
    "    # You might call a real API or Python library like pytz/dateutil in production.\n",
    "    return f\"The current local time in {tz} is 09:00 AM.\"\n",
    "\n",
    "# 2) Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# 3) Create the minimal Azure OpenAI client.\n",
    "azure_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# 4) Create the AssistantAgent, giving it access to the three tools.\n",
    "#    We mention them in the system_message so the model knows it can call them.\n",
    "agent = AssistantAgent(\n",
    "    name=\"multi_tool_agent\",\n",
    "    model_client=azure_client,\n",
    "    tools=[get_weather, convert_currency, get_time_in],\n",
    "    system_message=(\n",
    "        \"You are a helpful Azure test assistant. You have access to the following tools:\\n\"\n",
    "        \"1) get_weather(city: str) - Provides a weather report.\\n\"\n",
    "        \"2) convert_currency(amount: float, from_currency: str, to_currency: str) - Converts between currencies.\\n\"\n",
    "        \"3) get_time_in(tz: str) - Returns local time in a given timezone.\\n\\n\"\n",
    "        \"Only call these functions if the user is requesting relevant info.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5) Let’s define an async function that prompts for multiple tasks.\n",
    "async def demo_multi_tool_calls():\n",
    "    # We'll ask a series of user queries that might trigger each function separately.\n",
    "    user_prompts = [\n",
    "        \"Hi there! Could you tell me the weather in Berlin?\",\n",
    "        \"Actually, could you also convert 100 USD to EUR?\",\n",
    "        \"What's the local time in Tokyo right now?\"\n",
    "    ]\n",
    "\n",
    "    for prompt in user_prompts:\n",
    "        print(f\"---------- user ----------\\n{prompt}\")\n",
    "        # Using run_stream for streaming the conversation to the console\n",
    "        await Console(agent.run_stream(task=prompt))\n",
    "        print(\"\\n\")\n",
    "\n",
    "# 6) Run the demonstration in Jupyter by simply 'await'-ing the function.\n",
    "await demo_multi_tool_calls()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
