{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building with AutoGen \n",
    "### Please Complete the **[environment setup](part1_environment_setup.ipynb)** first before progressing with the notebook!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Starting Building with AutoGen \n",
    "Let's start with a simple example of how AutoGen is integrated Azure OpenAI. \n",
    "The example will confirm Azure OpenAI endpoints and keys are correctly configured and that AutoGen is installed and working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Hello! Are you working?\n",
      "---------- azure_test_agent ----------\n",
      "Hello! Yes, I'm here to help. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a minimal Azure OpenAI client.\n",
    "azure_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create an assistant agent with a simple system message.\n",
    "agent = AssistantAgent(\n",
    "    name=\"azure_test_agent\",\n",
    "    model_client=azure_client,\n",
    "    system_message=\"You are a helpful Azure test assistant.\"\n",
    ")\n",
    "\n",
    "async def test_connection():\n",
    "    user_input = \"Hello! Are you working?\"\n",
    "    await Console(agent.run_stream(task=user_input))\n",
    "\n",
    "await test_connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **autogen** framework provides multiple agent roles—such as `AssistantAgent`, `UserAgent`, `FunctionAgent` (for function or tool calls), and `MultiAgent` (for orchestrating multiple participants)—each designed for specialized behaviors in a conversation. For example:\n",
    "\n",
    "- `AssistantAgent`: Represents a helpful AI assistant.\n",
    "- `FunctionAgent`: Handles specific tools or API calls.\n",
    "- `MultiAgent`: Coordinates interactions among different agents.\n",
    "\n",
    "This modular design makes it straightforward to build and manage multi-turn, multi-role dialogues, assigning clear, distinct responsibilities to each agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AssistantAgent` we used here is a high-level wrapper around a language model client (such as an AzureOpenAI model) that manages:\n",
    "\n",
    "1. **Conversational Context**: It keeps track of all previous exchanges and organizes them into a coherent dialog.\n",
    "2. **System or Instruction Prompt**: You can give it a “system message” that defines the overarching instructions or persona, such as:\n",
    "   > \"You are a helpful Azure test assistant.\"\n",
    "\n",
    "By consolidating these elements, `AssistantAgent` simplifies the process of building chat interfaces on top of LLMs, handling how user messages and model responses flow, and ensuring all conversation logic is neatly contained in a single agent object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Function Calling Example \n",
    "\n",
    "Function calling in the context of modern LLMs (Large Language Models) lets the model “call” a function (or tool) whenever it detects the user’s query needs that function’s capabilities. Rather than returning a text-only answer, the LLM returns structured arguments for the function, which your application or framework executes. \\\n",
    "\n",
    "In AutoGen’s AssistantAgent, every function you register is treated as a “tool” that the LLM can invoke. When a user prompt suggests one of those tools is needed, the model produces a structured “function call” specifying which tool to use and the arguments to pass. The AssistantAgent runs that function in your Python environment, then feeds the result back to the model. Finally, the model incorporates that real-world data—whether weather forecasts, currency exchanges, or local times—into its final, user-facing response. This design keeps things neat: the LLM decides what needs doing, and your Python code handles how it’s done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n",
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_KYmYDQCeWctdFOeoQSuQNHKq', arguments='{\"city\":\"Berlin\"}', name='get_weather')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='The current weather in Berlin is 25°C, sunny.', call_id='call_KYmYDQCeWctdFOeoQSuQNHKq', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "The current weather in Berlin is 25°C, sunny.\n",
      "\n",
      "\n",
      "---------- user ----------\n",
      "Actually, could you also convert 100 USD to EUR?\n",
      "---------- user ----------\n",
      "Actually, could you also convert 100 USD to EUR?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_DCJBY8F8nPwCFIhwFVY31ckb', arguments='{\"amount\":100,\"from_currency\":\"USD\",\"to_currency\":\"EUR\"}', name='convert_currency')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='100.0 USD is approximately 110.00 EUR.', call_id='call_DCJBY8F8nPwCFIhwFVY31ckb', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "100.0 USD is approximately 110.00 EUR.\n",
      "\n",
      "\n",
      "---------- user ----------\n",
      "What's the local time in Tokyo right now?\n",
      "---------- user ----------\n",
      "What's the local time in Tokyo right now?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_7eRowPgwatHL2bH9zQIIwSsq', arguments='{\"tz\":\"Asia/Tokyo\"}', name='get_time_in')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='The current local time in Asia/Tokyo is 09:00 AM.', call_id='call_7eRowPgwatHL2bH9zQIIwSsq', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "The current local time in Asia/Tokyo is 09:00 AM.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# 1) Define three different \"tool\" functions that your LLM might call.\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns a fake weather report for demonstration.\"\"\"\n",
    "    return f\"The current weather in {city} is 25°C, sunny.\"\n",
    "\n",
    "async def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"Returns a simple stub result for currency conversion.\"\"\"\n",
    "    # In real scenarios, you'd call a currency conversion API here.\n",
    "    # We'll just do a mock 1:1.1 ratio for demonstration.\n",
    "    conversion_rate = 1.1\n",
    "    converted_amount = amount * conversion_rate\n",
    "    return f\"{amount} {from_currency.upper()} is approximately {converted_amount:.2f} {to_currency.upper()}.\"\n",
    "\n",
    "async def get_time_in(tz: str) -> str:\n",
    "    \"\"\"Returns a mock local time for the given timezone.\"\"\"\n",
    "    # You might call a real API or Python library like pytz/dateutil in production.\n",
    "    return f\"The current local time in {tz} is 09:00 AM.\"\n",
    "\n",
    "# 2) Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# 3) Create the minimal Azure OpenAI client.\n",
    "azure_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# 4) Create the AssistantAgent, giving it access to the three tools.\n",
    "#    We mention them in the system_message so the model knows it can call them.\n",
    "agent = AssistantAgent(\n",
    "    name=\"multi_tool_agent\",\n",
    "    model_client=azure_client,\n",
    "    tools=[get_weather, convert_currency, get_time_in],\n",
    "    system_message=(\n",
    "        \"You are a helpful Azure test assistant. You have access to the following tools:\\n\"\n",
    "        \"1) get_weather(city: str) - Provides a weather report.\\n\"\n",
    "        \"2) convert_currency(amount: float, from_currency: str, to_currency: str) - Converts between currencies.\\n\"\n",
    "        \"3) get_time_in(tz: str) - Returns local time in a given timezone.\\n\\n\"\n",
    "        \"Only call these functions if the user is requesting relevant info.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5) Let’s define an async function that prompts for multiple tasks.\n",
    "async def demo_multi_tool_calls():\n",
    "    # We'll ask a series of user queries that might trigger each function separately.\n",
    "    user_prompts = [\n",
    "        \"Hi there! Could you tell me the weather in Berlin?\",\n",
    "        \"Actually, could you also convert 100 USD to EUR?\",\n",
    "        \"What's the local time in Tokyo right now?\"\n",
    "    ]\n",
    "\n",
    "    for prompt in user_prompts:\n",
    "        print(f\"---------- user ----------\\n{prompt}\")\n",
    "        # Using run_stream for streaming the conversation to the console\n",
    "        await Console(agent.run_stream(task=prompt))\n",
    "        print(\"\\n\")\n",
    "\n",
    "# 6) Run the demonstration in Jupyter by simply 'await'-ing the function.\n",
    "await demo_multi_tool_calls()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Function Calling with Structured Outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n",
      "---------- user ----------\n",
      "Hi there! Could you tell me the weather in Berlin?\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionCall(id='call_TZRIhIUgzPs1O3QiCsiM1DZR', arguments='{\"city\":\"Berlin\"}', name='get_weather')]\n",
      "---------- multi_tool_agent ----------\n",
      "[FunctionExecutionResult(content='The current weather in Berlin is 25°C, sunny.', call_id='call_TZRIhIUgzPs1O3QiCsiM1DZR', is_error=False)]\n",
      "---------- multi_tool_agent ----------\n",
      "The current weather in Berlin is 25°C, sunny.\n",
      "\n",
      "---------- user ----------\n",
      "Please convert 100 USD to EUR.\n",
      "---------- user ----------\n",
      "Please convert 100 USD to EUR.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool  # ✅ Correct import\n",
    "\n",
    "# 1) Apply nest_asyncio (fixes Jupyter asyncio issues)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 2) Pydantic model for structured outputs.\n",
    "class QueryResponse(BaseModel):\n",
    "    weather_report: Optional[str] = None\n",
    "    currency_info: Optional[str] = None\n",
    "    local_time: Optional[str] = None\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "# 3) Updated function definitions (sync versions).\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns a fake weather report.\"\"\"\n",
    "    return f\"The current weather in {city} is 25°C, sunny.\"\n",
    "\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"Returns a stub currency conversion.\"\"\"\n",
    "    rate = 1.1\n",
    "    result = amount * rate\n",
    "    return f\"{amount} {from_currency.upper()} is ~{result:.2f} {to_currency.upper()}.\"\n",
    "\n",
    "def get_time_in(tz: str) -> str:\n",
    "    \"\"\"Returns a mock local time.\"\"\"\n",
    "    return f\"The current local time in {tz} is 09:00 AM.\"\n",
    "\n",
    "# 4) Convert each function into FunctionTool for structured calling.\n",
    "tool_get_weather = FunctionTool(get_weather, description=\"Get the current weather for a city.\")\n",
    "tool_convert_currency = FunctionTool(convert_currency, description=\"Convert an amount between currencies.\")\n",
    "tool_get_time_in = FunctionTool(get_time_in, description=\"Get the current time in a timezone.\")\n",
    "\n",
    "# 5) Load env variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# 6) Create a minimal Azure OpenAI client.\n",
    "azure_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 7) Create an AssistantAgent with FunctionTool + enforced JSON output.\n",
    "agent = AssistantAgent(\n",
    "    name=\"multi_tool_agent\",\n",
    "    model_client=azure_client,\n",
    "    tools=[tool_get_weather, tool_convert_currency, tool_get_time_in],\n",
    "    system_message=(\n",
    "        \"You are a helpful Azure test assistant. You have access to:\\n\"\n",
    "        \"1) get_weather(city: str) - Fetches current weather details.\\n\"\n",
    "        \"2) convert_currency(amount: float, from_currency: str, to_currency: str) - Converts currency values.\\n\"\n",
    "        \"3) get_time_in(tz: str) - Retrieves the local time for a given timezone.\\n\\n\"\n",
    "        \"⚠️ **STRICT OUTPUT FORMAT REQUIRED:**\\n\"\n",
    "        \"Your response MUST be in **valid JSON** formatted as follows:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"weather_report\": string or null,\\n'\n",
    "        '  \"currency_info\": string or null,\\n'\n",
    "        '  \"local_time\": string or null,\\n'\n",
    "        '  \"notes\": string or null\\n'\n",
    "        \"}\\n\"\n",
    "        \"Ensure that your response **ONLY contains JSON**. No extra text or explanations.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 8) Demo function that prompts multiple tasks.\n",
    "async def demo_multi_tool_calls():\n",
    "    user_prompts = [\n",
    "        \"Hi there! Could you tell me the weather in Berlin?\",\n",
    "        \"Please convert 100 USD to EUR.\",\n",
    "        \"What's the local time in Tokyo right now?\"\n",
    "    ]\n",
    "    for prompt in user_prompts:\n",
    "        print(f\"---------- user ----------\\n{prompt}\")\n",
    "        await Console(agent.run_stream(task=prompt))\n",
    "        print()\n",
    "\n",
    "# 9) Execute the function in a Jupyter cell.\n",
    "await demo_multi_tool_calls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the previous iteration, which simply allowed an LLM-powered assistant to call basic functions, the updated code enhances reliability, structure, and execution flow. The original version used standard Python functions as tools, but lacked strict enforcement of structured outputs, meaning responses could be inconsistent or require additional post-processing. In contrast, the improved version wraps functions using FunctionTool from autogen_core.tools, ensuring proper argument parsing and structured execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
